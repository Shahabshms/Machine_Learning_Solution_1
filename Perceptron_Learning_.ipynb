{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Perceptron Learning .ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNCJZ3Zrw/+x5C31cTlfLt5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shahabshms/Machine_Learning_Solution_1/blob/main/Perceptron_Learning_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZANUcP1VXpH"
      },
      "source": [
        "# Problem 1: Perceptron Learning\n",
        "\n",
        "Consider the data set (perceptron.data) attached to this homework. This data file consists of $M$ data elements of the form $(x_1^{(m)}, x_2^{(m)}, x_3^{(m)}, x_4^{(m)}, y^{(m)})$ where $x_1^{(m)}, \\ldots, x_4^{(m)}\\in\\mathbb{R}$ define a data point in $\\mathbb{R}^4$ and $y^{(m)}\\in\\{-1,1\\}$  is the corresponding class label."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Lpvpj5JVjh5"
      },
      "source": [
        "##1.\n",
        "In class we saw how to use the perceptron algorithm to minimize the following loss function. $$f(w,b) = \\frac{1}{M}\\sum_{m=1}^{M}\\max\\{0,-y^{(m)}\\cdot(w^Tx^{(m)}+b)\\}$$ What is the smallest, in terms of number of data points, two-dimensional data set containing both class labels on which the perceptron algorithm, with step size one, fails to converge? Use this example to explain why the method may fail to converge more generally.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCjAYZl7gHvq"
      },
      "source": [
        "Two points at one exact location are not seperable. So the algorithm fails to provide us with a linear seperator. However, if the data set is required to be seprable, we can take three points on one line such that the point in the middle belongs to a different class than the other two. Note that the main point of this question is that the step size does not matter. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmXhOlV1cwQA"
      },
      "source": [
        "$$\\frac{\\partial f(w,b)}{\\partial w_i} = \\frac{1}{M}\\sum_{m=1}^{M}\\begin{cases} 0 & - y^{(m)}\\cdot(w^T x^{(m)}+ b) < 0 \\\\ -y^{(m)}x^{(m)}_i & - y^{(m)}\\cdot(w^T x^{(m)}+ b) > 0  \\\\ 0^{(*)}& - y^{(m)}\\cdot(w^T x^{(m)}+ b) = 0\\end{cases}$$\n",
        "\n",
        "\n",
        "$$\\nabla_w f(w,b) = [\\frac{\\partial f(w,b)}{\\partial w_1},\\dots,\\frac{\\partial f(w,b)}{\\partial w_4}]$$\n",
        "\n",
        "$$\\nabla_w f(w,b) = \\frac{1}{M}\\sum_{m=1}^{M} \\begin{cases} 0 & - y^{(m)}\\cdot(w^T x^{(m)} + b) < 0 \\\\ -y^{(m)}x^{(m)} & - y^{(m)}\\cdot(w^T x^{(m)}+ b) > 0 \\\\ 0& - y^{(m)}\\cdot(w^T x^{(m)}+ b) = 0\\end{cases}$$\n",
        "\n",
        "$(*)$ the function is not differentiable at this point and its subgradient can be anything between $0$ and $-y^{(m)}x^{(m)}_i$. $0$ is just the easiest one to pick.  \n",
        "\n",
        "\n",
        "$$\\frac{\\partial f(w,b)}{\\partial b} = \\frac{1}{M}\\sum_{m=1}^{M}\\begin{cases}0 & - y^{(m)}\\cdot(w^T x^{(m)}+ b) < 0 \\\\ -y^{(m)} & - y^{(m)}\\cdot(w^T x^{(m)}+ b) > 0  \\\\  0^{(**)}& - y^{(m)}\\cdot(w^T x^{(m)}+ b) = 0\\end{cases}$$\n",
        "\n",
        "\n",
        "$$\\nabla_b f(w,b) = [\\frac{\\partial f(w,b)}{\\partial b}]$$\n",
        "\n",
        "$(**)$ the function is not differentiable at this point and its subgradient can be anything between $0$ and $-y^{(m)}$. $0$ is just the easiest one to pick.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTZxSXc80W7S"
      },
      "source": [
        "##2.\r\n",
        "Consider the following alternative loss function. $$g(w,b) = \\frac{1}{M}\\sum_{m=1}^{M}\\max\\{0,1-y^{(m)}\\cdot(w^Tx^{(m)}+b)\\}^2$$\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6BQYti6ybIc"
      },
      "source": [
        "\r\n",
        "###(a)\r\n",
        "If the data is linearly separable, does this loss function have any local optima that are not global optima?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GK5UOraInIZp"
      },
      "source": [
        "No. We argue that this objective function is convex, hence does not have a local optima that is not a global minimum. In order to prove this argument, we go through the following three steps, each based on known facts that we have already seen. \n",
        "\n",
        "1.   Maximum of convex functions is convex ($g(x) = \\max\\{f_1(x) + f_2(x)\\}$).\n",
        "\n",
        "  $0$ and $1-y^{(m)}\\cdot(w^T x^{(m)} + b)$ are both linear functions. Linear functions are convex, so as the function $\\max\\{0,1-y^{(m)}\\cdot(w^T x^{(m)} + b)\\}$. (Linear functions are also concave)\n",
        "\n",
        "\n",
        "\n",
        "2.   Composition of convex functions is convex ($g(x) = f_1(f_2(x))$).\n",
        "\n",
        "  The function $\\max\\{0,1-y^{(m)}\\cdot(w^T x^{(m)} + b)\\}^2$ is obtained from composing $\\max\\{0,1-y^{(m)}\\cdot(w^T x^{(m)} + b)\\}$ in $x^2$. In 1. we showed that $\\max\\{0,1-y^{(m)}\\cdot(w^T x^{(m)} + b)\\}$ is convex. And $x^2$ is convex indeed. So $\\max\\{0,1-y^{(m)}\\cdot(w^T x^{(m)} + b)\\}^2$ is convex.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "3.   Summation of convex functions is convex ($f(x) = f_1(x) + f_2(x)$).\n",
        "\n",
        "  In 2. we showed that $\\max\\{0,1-y^{(m)}\\cdot(w^T x^{(m)} + b)\\}^2$ is convex, regardless of $m$. This shows that $\\sum_{m=1}^{M}\\max\\{0,1-y^{(m)}\\cdot(w^Tx^{(m)}+b)\\}^2$ is convex and this wraps the proof. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnCwzH3A1GuC"
      },
      "source": [
        "###(b)\r\n",
        "\r\n",
        "For each optimization strategy below, report the number of iterations that it takes to find a perfect classifier for the data, the values of w and b for the first three iterations, and the final weights and bias. Each descent procedure should start from the initial point $$\r\n",
        "w^0 = \\left[\r\n",
        "    \\begin{array}\\\\\r\n",
        "        0 \\\\\r\n",
        "        0 \\\\\r\n",
        "        0 \\\\\r\n",
        "        0 \\\\\r\n",
        "    \\end{array}\r\n",
        "\\right] \r\n",
        "\\qquad b^0=0\r\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ld1IfmAgWpkC",
        "outputId": "d6a90d6b-b996-4d53-ec82-7d1f88677f90"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sys, os\n",
        "# reading csv files\n",
        "col_names = ['x1','x2','x3','x4','y']\n",
        "!wget -nc https://personal.utdallas.edu/~shahab.shams/files/ML_Spring_2021/perceptron.data\n",
        "data =  pd.read_csv('perceptron.data', sep=\",\" , names = col_names)\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-01 19:09:00--  https://personal.utdallas.edu/~shahab.shams/files/ML_Spring_2021/perceptron.data\n",
            "Resolving personal.utdallas.edu (personal.utdallas.edu)... 129.110.182.249\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 53175 (52K)\n",
            "Saving to: ‘perceptron.data’\n",
            "\n",
            "perceptron.data      30%[=====>              ]  15.62K  --.-KB/s    in 8m 26s  \n",
            "\n",
            "2021-03-01 19:17:29 (31.6 B/s) - Read error at byte 16000/53175 (Connection reset by peer). Retrying.\n",
            "\n",
            "--2021-03-01 19:17:30--  (try: 2)  https://personal.utdallas.edu/~shahab.shams/files/ML_Spring_2021/perceptron.data\n",
            "Connecting to personal.utdallas.edu (personal.utdallas.edu)|129.110.182.249|:443... connected.\n",
            "HTTP request sent, awaiting response... 206 Partial Content\n",
            "Length: 53175 (52K), 37175 (36K) remaining\n",
            "Saving to: ‘perceptron.data’\n",
            "\n",
            "perceptron.data     100%[++++++=============>]  51.93K  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-03-01 19:17:31 (424 KB/s) - ‘perceptron.data’ saved [53175/53175]\n",
            "\n",
            "           x1        x2        x3        x4  y\n",
            "0   -4.617544 -2.469679 -1.967661  1.813356 -1\n",
            "1   -1.110969 -2.592820  1.149165  0.572509 -1\n",
            "2    1.164321  2.300245 -0.660355  2.833743 -1\n",
            "3   -2.518213 -3.619048  1.673304  0.030407 -1\n",
            "4    4.821442  2.037048  2.348538 -1.683379  1\n",
            "..        ...       ...       ...       ... ..\n",
            "994  2.253275  0.877464  3.710523 -4.829729  1\n",
            "995 -4.783584  2.355449 -3.460199 -3.760533 -1\n",
            "996 -0.102361 -1.405714  0.379720 -4.648531  1\n",
            "997  2.256090  0.495370  0.790985  1.854742 -1\n",
            "998 -1.023419  4.061322  0.148172  2.572487 -1\n",
            "\n",
            "[999 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0fiVeR7bL1T",
        "outputId": "d6ed0408-6730-468a-9518-ba0a0b8397a2"
      },
      "source": [
        "Y = data['y'].values\n",
        "print('Y dimention: ',Y.shape)\n",
        "X = data[['x1','x2','x3','x4']].values\n",
        "print('X dimnetion: ',X.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Y dimention:  (999,)\n",
            "X dimnetion:  (999, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz0gLeM-AXvA"
      },
      "source": [
        "def test(w,b):\n",
        "  Y_pred = np.sign(X.dot(w) + b)\n",
        "  error = sum([int(Y[i] != Y_pred[i]) for i in range(len(Y))])\n",
        "  # print(error,' missclassified out of ',Y.shape[0], 'total.\\n')\n",
        "  return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMEHiqyL3L3J"
      },
      "source": [
        "####i. \n",
        "Standard subgradient descent with the step size $\\gamma_t = 1$ for each iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNOfxVlYeutT"
      },
      "source": [
        "$$\\frac{\\partial g(w,b)}{\\partial w_i} = \\frac{1}{M}\\sum_{m=1}^{M}\\begin{cases} 0 & 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) < 0 \\\\ -2y^{(m)}x^{(m)}_i(1 - y^{m}\\cdot(w^T x^{(m)} +b)) & 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) > 0  \\\\ 0^{(*)}& 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) = 0\\end{cases}$$\n",
        "\n",
        "\n",
        "$$\\nabla_w g(w,b) = [\\frac{\\partial g(w,b)}{\\partial w_1},\\dots,\\frac{\\partial g(w,b)}{\\partial w_4}]$$\n",
        "\n",
        "$$\\nabla_w g(w,b) = \\frac{1}{M}\\sum_{m=1}^{M} \\begin{cases} 0 & 1 - y^{(m)}\\cdot(w^T x^{(m)} + b) < 0 \\\\ -2y^{(m)}x^{(m)}(1-y^{(m)}\\cdot(w^Tx^{(m)} + b)) & 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) > 0 \\\\ 0& 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) = 0\\end{cases}$$\n",
        "\n",
        "$(*)$ $g(w,b)$ is not differentiable at this point and its subgradient can be anything between $0$ and $-2y^{(m)}x^{(m)}_i(1 - y^{m}\\cdot(w^T x^{(m)} +b))$. $0$ is just the easiest to pick.  \n",
        "\n",
        "\n",
        "----\n",
        "\n",
        "$$\\frac{\\partial g(w,b)}{\\partial b} = \\frac{1}{M}\\sum_{m=1}^{M}\\begin{cases}0 & 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) < 0 \\\\ -2y^{(m)}\\cdot(1 - y^{m}(w^T x^{(m)} +b)) & 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) > 0  \\\\  0^{(**)}& 1 - y^{(m)}\\cdot(w^T x^{(m)}+ b) = 0\\end{cases}$$\n",
        "\n",
        "\n",
        "$$\\nabla_b g(w,b) = [\\frac{\\partial g(w,b)}{\\partial b}]$$\n",
        "\n",
        "$(**)$ $g(w,b)$ is not differentiable at this point and its subgradient can be anything between $0$ and $-2y^{(m)}\\cdot(1 - y^{m}(w^T x^{(m)} +b))$. $0$ is just the easiest to pick.  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0zhqFwFdKtx"
      },
      "source": [
        "def get_gradient_standard(w,b):\n",
        "  g_w = np.zeros([1,4])\n",
        "  g_b = 0\n",
        "  for m in range(Y.shape[0]):\n",
        "    if 1 - Y[m]*(X[m].dot(w) + b) > 0:\n",
        "      g_w += -2 * Y[m] * X[m] * (1 - Y[m]*(X[m].dot(w) + b))\n",
        "      g_b += -2 * Y[m] * (1 - Y[m]*(X[m].dot(w) + b))\n",
        "    if 1 - Y[m]*(X[m].dot(w) + b) < 0:\n",
        "      g_w += 0\n",
        "      g_b += 0\n",
        "    if 1 - Y[m]*(X[m].dot(w) + b) == 0:\n",
        "      g_w += 0\n",
        "      g_b += 0\n",
        "  return [g_w/Y.shape[0],g_b/Y.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2EEYwaDbsTx"
      },
      "source": [
        "from progressbar import ProgressBar\n",
        "def standard_gradient_descent(w,b,itrs,step_size = 1):\n",
        "  pbar = ProgressBar()\n",
        "  for it in pbar(range(itrs)):\n",
        "    [g_w,g_b] = get_gradient_standard(w,b)\n",
        "    w = w - step_size * g_w.T\n",
        "    b = b - step_size * g_b\n",
        "\n",
        "    if True in np.isnan(w) or True in np.isnan(b):\n",
        "      print('\\nNubmer of iterations: ', it)\n",
        "      print('\\n !!Overflow!! \\n')\n",
        "      return [w,b]\n",
        "\n",
        "    if it % 250 == 0:\n",
        "      print('\\nw: ',w.T)\n",
        "      print('b: ',b)\n",
        "      print(test(w,b),' missclassified out of ',Y.shape[0], 'total.\\n')\n",
        "    if test(w,b) == 0:\n",
        "      print('\\nw: ',w.T)\n",
        "      print('b: ',b)\n",
        "      print(test(w,b),' missclassified out of ',Y.shape[0], 'total.\\n')\n",
        "      print('Nubmer of iterations: ', it)\n",
        "      return [w,b]\n",
        "\n",
        "  return [w,b]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTZgvlyEIKFR",
        "outputId": "ae843faf-f278-405b-ba5e-eb8f254bfacf"
      },
      "source": [
        "def standard(itrs = 1000,step_size = 1):\n",
        "  w = np.zeros([4,1])\n",
        "  b = 0\n",
        "  [w,b] = standard_gradient_descent(w,b,itrs,step_size)\n",
        "\n",
        "standard()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0% (6 of 1000) |                       | Elapsed Time: 0:00:00 ETA:   0:00:36"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 2.5593007   0.91720162 -0.21666124 -3.34649272]]\n",
            "b:  [-0.71071071]\n",
            "139  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25% (254 of 1000) |#####                | Elapsed Time: 0:00:09 ETA:   0:00:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[-1.60154178e+194 -4.73082015e+193  5.04759139e+193 -3.22875102e+194]]\n",
            "b:  [-5.79908935e+193]\n",
            "357  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 39% (390 of 1000) |########             | Elapsed Time: 0:00:13 ETA:   0:00:20/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in add\n",
            "  \n",
            " 39% (393 of 1000) |########             | Elapsed Time: 0:00:13 ETA:   0:00:20"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Nubmer of iterations:  393\n",
            "\n",
            " !!Overflow!! \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in add\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in add\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in subtract\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ky8_umWO3dZx"
      },
      "source": [
        "####ii. \r\n",
        "Stochastic subgradient descent where exactly one component of the sum is chosen to approximate the gradient at each iteration. Instead of picking a random component at each iteration, you should iterate through the data set starting with the first element, then the second, and so on until the $M^{th}$ element, at which point you should start back at the beginning again. Again, use the step size $\\gamma_t = 1$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nVwaszplVNqb"
      },
      "source": [
        "def get_gradient_stochastic(w,b,m):\n",
        "  g_w = np.zeros([1,4])\n",
        "  g_b = 0\n",
        "  if 1 - Y[m]*(X[m].dot(w) + b) > 0:\n",
        "    g_w += -2 * Y[m] * X[m] * (1 - Y[m]*(X[m].dot(w) + b))\n",
        "    g_b += -2 * Y[m] * (1 - Y[m]*(X[m].dot(w) + b))\n",
        "  if 1 - Y[m]*(X[m].dot(w) + b) < 0:\n",
        "    g_w += 0\n",
        "    g_b += 0\n",
        "  if 1 - Y[m]*(X[m].dot(w) + b) == 0:\n",
        "    g_w += 0\n",
        "    g_b += 0\n",
        "  return [g_w/Y.shape[0],g_b/Y.shape[0]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2enTiveEtMlf"
      },
      "source": [
        "from progressbar import ProgressBar\n",
        "def stochastic_gradient_descent(w,b,itrs,step_size = 1):\n",
        "  pbar = ProgressBar()\n",
        "  for it in pbar(range(itrs)):\n",
        "    for m in range(Y.shape[0]):\n",
        "      [g_w,g_b] = get_gradient_stochastic(w,b,m)\n",
        "      w = w - step_size * g_w.T\n",
        "      b = b - step_size * g_b\n",
        "\n",
        "\n",
        "      if True in np.isnan(w) or True in np.isnan(b):\n",
        "        print('\\nNubmer of iterations: ', it)\n",
        "        print('!!Overflow!!')\n",
        "        return [w,b]\n",
        "      if m == 0 and it%250 == 0:\n",
        "        print('\\nw: ',w.T)\n",
        "        print('b: ',b)\n",
        "        print(test(w,b),' missclassified out of ',Y.shape[0], 'total.\\n')\n",
        "      if m== 0 and test(w,b)  == 0:\n",
        "        print('\\nw: ',w.T)\n",
        "        print('b: ',b)\n",
        "        print(test(w,b),' missclassified out of ',Y.shape[0], 'total.\\n')\n",
        "        print('Nubmer of epochs: ', it)\n",
        "        print('Nubmer of iterations: ', it*Y.shape[0])\n",
        "        return [w,b]\n",
        "  return [w,b]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fltb_heUVkTv",
        "outputId": "9d7b3c78-c681-4871-ec9a-fdea6f569712"
      },
      "source": [
        "def stochastic():\n",
        "  w = np.zeros([4,1])\n",
        "  b = 0\n",
        "  itrs = 1000\n",
        "  [w,b] = stochastic_gradient_descent(w,b,itrs)\n",
        "\n",
        "\n",
        "stochastic()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0% (2 of 1000) |                       | Elapsed Time: 0:00:00 ETA:   0:00:54"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 0.00924433  0.0049443   0.00393926 -0.00363034]]\n",
            "b:  [-0.002002]\n",
            "216  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25% (253 of 1000) |#####                | Elapsed Time: 0:00:13 ETA:   0:00:44"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.66237357  0.58135843  0.01358617 -1.90717079]]\n",
            "b:  [-3.54927803]\n",
            "2  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50% (502 of 1000) |##########           | Elapsed Time: 0:00:25 ETA:   0:00:29"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 2.09009769  0.73349196  0.01451216 -2.40140247]]\n",
            "b:  [-4.52517327]\n",
            "1  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 72% (727 of 1000) |###############      | Elapsed Time: 0:00:37 ETA:   0:00:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 2.38483517  0.83847153  0.01542512 -2.744536  ]]\n",
            "b:  [-5.20026137]\n",
            "0  missclassified out of  999 total.\n",
            "\n",
            "Nubmer of epochs:  728\n",
            "Nubmer of iterations:  727272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHw3FIPy3ygR"
      },
      "source": [
        "####iii. \n",
        "How does the rate of convergence change as you change the step size? Provide some example step sizes to back up your statements."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9Ev_SEtBWTp"
      },
      "source": [
        "Large step sizes may result in the algorithm to diverge. So, one might think that taking a very small step size is alway the best starategy. However, too small step sizes take too long converge, trivially because the update at each iteration is too small. And if the objective function has local optimas, too small step sizes increase the change of stucking in a local optimum. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufqfzYb1s48C",
        "outputId": "1f94ba86-7c4c-446a-faa6-49a810a6d12f"
      },
      "source": [
        "for step_size in [0.5,0.4,0.2,0.1]:\n",
        "  print('\\n\\nwith the step size: ',step_size,)\n",
        "  standard(itrs = 5000, step_size = step_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0% (2 of 5000) |                       | Elapsed Time: 0:00:00 ETA:   0:05:02"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "with the step size:  0.5\n",
            "\n",
            "w:  [[ 1.27965035  0.45860081 -0.10833062 -1.67324636]]\n",
            "b:  [-0.35535536]\n",
            "139  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5% (254 of 5000) |#                    | Elapsed Time: 0:00:11 ETA:   0:03:44"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[-9.69660439e+82 -1.01460389e+82  2.57977238e+82 -2.62180084e+83]]\n",
            "b:  [-8.07711061e+82]\n",
            "318  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10% (503 of 5000) |##                   | Elapsed Time: 0:00:23 ETA:   0:03:47"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[-1.14390531e+168 -1.19692495e+167  3.04334920e+167 -3.09293004e+168]]\n",
            "b:  [-9.52854147e+167]\n",
            "318  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15% (754 of 5000) |###                  | Elapsed Time: 0:00:35 ETA:   0:03:20"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[-1.34946142e+253 -1.41200853e+252  3.59022928e+252 -3.64871964e+253]]\n",
            "b:  [-1.12407898e+253]\n",
            "318  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 17% (899 of 5000) |###                  | Elapsed Time: 0:00:42 ETA:   0:03:18/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in add\n",
            "  \n",
            " 18% (902 of 5000) |###                  | Elapsed Time: 0:00:42 ETA:   0:03:17/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in add\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in add\n",
            "  import sys\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in subtract\n",
            "  \n",
            "  0% (2 of 5000) |                       | Elapsed Time: 0:00:00 ETA:   0:06:23"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Nubmer of iterations:  902\n",
            "\n",
            " !!Overflow!! \n",
            "\n",
            "\n",
            "\n",
            "with the step size:  0.4\n",
            "\n",
            "w:  [[ 1.02372028  0.36688065 -0.08666449 -1.33859709]]\n",
            "b:  [-0.28428428]\n",
            "139  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5% (254 of 5000) |#                    | Elapsed Time: 0:00:10 ETA:   0:03:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.30158345  0.4466716   0.01647827 -1.48994717]]\n",
            "b:  [-2.74385917]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10% (505 of 5000) |##                   | Elapsed Time: 0:00:21 ETA:   0:03:22"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.56173303  0.53484349  0.01730492 -1.79062651]]\n",
            "b:  [-3.3286149]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15% (755 of 5000) |###                  | Elapsed Time: 0:00:31 ETA:   0:02:58"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.76207883  0.60528038  0.01723191 -2.02081289]]\n",
            "b:  [-3.781651]\n",
            "1  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0% (2 of 5000) |                       | Elapsed Time: 0:00:00 ETA:   0:05:59"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.85119502  0.63709045  0.01662308 -2.12430955]]\n",
            "b:  [-3.98553004]\n",
            "0  missclassified out of  999 total.\n",
            "\n",
            "Nubmer of iterations:  878\n",
            "\n",
            "\n",
            "with the step size:  0.2\n",
            "\n",
            "w:  [[ 0.51186014  0.18344032 -0.04333225 -0.66929854]]\n",
            "b:  [-0.14214214]\n",
            "139  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5% (254 of 5000) |#                    | Elapsed Time: 0:00:11 ETA:   0:03:03"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.01848756  0.34764049  0.01334999 -1.16126252]]\n",
            "b:  [-2.11023967]\n",
            "4  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10% (505 of 5000) |##                   | Elapsed Time: 0:00:21 ETA:   0:03:06"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.24593396  0.42733163  0.01619136 -1.42561415]]\n",
            "b:  [-2.62017373]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15% (753 of 5000) |###                  | Elapsed Time: 0:00:32 ETA:   0:03:02"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.40065697  0.48015671  0.01736929 -1.60481994]]\n",
            "b:  [-2.9645739]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20% (1005 of 5000) |####                | Elapsed Time: 0:00:42 ETA:   0:02:54"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.52474002  0.52229288  0.01745354 -1.7481288 ]]\n",
            "b:  [-3.24463377]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25% (1254 of 5000) |#####               | Elapsed Time: 0:00:53 ETA:   0:02:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.63342977  0.55966641  0.01722062 -1.87298045]]\n",
            "b:  [-3.49127463]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30% (1504 of 5000) |######              | Elapsed Time: 0:01:03 ETA:   0:02:25"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.73182385  0.59453675  0.01736822 -1.98591311]]\n",
            "b:  [-3.71327479]\n",
            "2  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35% (1753 of 5000) |#######             | Elapsed Time: 0:01:14 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.82133717  0.62642594  0.01679967 -2.08960769]]\n",
            "b:  [-3.91716501]\n",
            "1  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0% (1 of 5000) |                       | Elapsed Time: 0:00:00 ETA:   0:10:09"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.85088243  0.63697813  0.01662486 -2.12394547]]\n",
            "b:  [-3.98481458]\n",
            "0  missclassified out of  999 total.\n",
            "\n",
            "Nubmer of iterations:  1837\n",
            "\n",
            "\n",
            "with the step size:  0.1\n",
            "\n",
            "w:  [[ 0.25593007  0.09172016 -0.02166612 -0.33464927]]\n",
            "b:  [-0.07107107]\n",
            "139  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  5% (254 of 5000) |#                    | Elapsed Time: 0:00:11 ETA:   0:03:20"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 0.81261273  0.27807322  0.01229323 -0.92982198]]\n",
            "b:  [-1.66289932]\n",
            "9  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 10% (505 of 5000) |##                   | Elapsed Time: 0:00:22 ETA:   0:03:24"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.01181193  0.3453917   0.01329073 -1.1536202 ]]\n",
            "b:  [-2.09556076]\n",
            "4  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 15% (755 of 5000) |###                  | Elapsed Time: 0:00:33 ETA:   0:03:08"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.14206121  0.39067983  0.01493116 -1.30411625]]\n",
            "b:  [-2.38581118]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 20% (1004 of 5000) |####                | Elapsed Time: 0:00:44 ETA:   0:02:46"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.24193419  0.42591194  0.01617666 -1.42095266]]\n",
            "b:  [-2.61119112]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 25% (1255 of 5000) |#####               | Elapsed Time: 0:00:54 ETA:   0:02:44"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.32559023  0.4547694   0.01671904 -1.51748261]]\n",
            "b:  [-2.79665904]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 30% (1503 of 5000) |######              | Elapsed Time: 0:01:05 ETA:   0:02:33"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.39759859  0.4791238   0.01733697 -1.60126654]]\n",
            "b:  [-2.95772725]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 35% (1755 of 5000) |#######             | Elapsed Time: 0:01:16 ETA:   0:02:19"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.46232419  0.50113233  0.01769782 -1.67635701]]\n",
            "b:  [-3.10321654]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 40% (2005 of 5000) |########            | Elapsed Time: 0:01:26 ETA:   0:02:11"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.52211891  0.52140362  0.01746407 -1.74511767]]\n",
            "b:  [-3.2386834]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 45% (2255 of 5000) |#########           | Elapsed Time: 0:01:37 ETA:   0:01:58"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.57820123  0.54043065  0.01723876 -1.80954524]]\n",
            "b:  [-3.36600085]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 50% (2503 of 5000) |##########          | Elapsed Time: 0:01:47 ETA:   0:01:52"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.63108226  0.5588369   0.01721829 -1.87028249]]\n",
            "b:  [-3.48595247]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 55% (2754 of 5000) |###########         | Elapsed Time: 0:01:58 ETA:   0:01:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.68146215  0.57668363  0.01730706 -1.92818372]]\n",
            "b:  [-3.59991308]\n",
            "3  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60% (3004 of 5000) |############        | Elapsed Time: 0:02:08 ETA:   0:01:24"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.72966562  0.59377463  0.0173716  -1.98343916]]\n",
            "b:  [-3.70842948]\n",
            "2  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 65% (3255 of 5000) |#############       | Elapsed Time: 0:02:19 ETA:   0:01:15"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.77552326  0.61008845  0.01710384 -2.03641325]]\n",
            "b:  [-3.81233409]\n",
            "1  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 70% (3503 of 5000) |##############      | Elapsed Time: 0:02:29 ETA:   0:01:01"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.81936112  0.62572171  0.01681153 -2.08731294]]\n",
            "b:  [-3.91264023]\n",
            "1  missclassified out of  999 total.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 73% (3686 of 5000) |##############      | Elapsed Time: 0:02:37 ETA:   0:00:56"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "w:  [[ 1.85096667  0.63700839  0.01662439 -2.12404356]]\n",
            "b:  [-3.98500714]\n",
            "0  missclassified out of  999 total.\n",
            "\n",
            "Nubmer of iterations:  3686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD_fitJr36w9"
      },
      "source": [
        "### (c)\r\n",
        "Does your subgradient descent implementation with step size one always converge using this loss? Explain."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_vzl4-FsZdp"
      },
      "source": [
        "No. As we saw, overflow forced the algorithm to stop. "
      ]
    }
  ]
}